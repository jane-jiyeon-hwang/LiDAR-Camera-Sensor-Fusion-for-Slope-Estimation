{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6abc10c",
   "metadata": {},
   "source": [
    "# Multimodal LiDAR-Camera Sensor Fusion Algorithm for Road Longitudinal Slope Estimation\n",
    "I utilized the outputs of pretrained vision models (semantic segmentation and YOLO) and developed a pipeline involving geometric calibration, 3D-to-2D projection, and DBSCAN based clustering to precisely extract road-surface points. Traditional methods suffered from high error rates due to noise from roadside objects—such as guardrails, trees, and vehicles-being mistakenly included during image-LiDAR alignment. To address this, I developed a DBSCAN based road surface extraction algorithm that effectively removes such noise, ultimately reducing longitudinal slope estimation error by approximately 30%. \n",
    "####  Data Availability\n",
    "The raw data used in this project is **corporate confidential data** and cannot be publicly shared. Therefore, this repository contains only the analysis code (ipynb) without the original dataset. For security reasons, all sensitive information and paths have been removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38456845",
   "metadata": {},
   "source": [
    "## Sample Outputs\n",
    "\n",
    "### Raw Inputs\n",
    "<div align=\"center\" style=\"display: flex; justify-content: center; gap: 10px;\">\n",
    "  <div style=\"text-align: center; width: 30%;\">\n",
    "    <img src=\"./images/364804.999997.jpg\" width=\"100%\" />\n",
    "    <p><b>Original Camera Image</b></p>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; width: 30%;\">\n",
    "    <img src=\"./images/364804.999997_mask_rgb.png\" width=\"100%\" />\n",
    "    <p><b>Semantic Segmentation Output</b></p>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; width: 30%;\">\n",
    "    <img src=\"./images/364804.999997_raw.png\" width=\"100%\" />\n",
    "    <p><b>Raw LiDAR Point Cloud</b></p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Final Outputs\n",
    "<div align=\"center\">\n",
    "  <img src=\"./images/364804.999997_Final_4.png\" width=\"45%\" />\n",
    "  <img src=\"./images/364804.999997_Final_5.png\" width=\"45%\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e939db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json, warnings, math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173fcd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "pcd_dir = '/Users/jiyeonhwang/Downloads/서울대 교통계획연구실/도도/도도 종단경사/테스트베드/lidar'\n",
    "mask_dir = '/Users/jiyeonhwang/Downloads/서울대 교통계획연구실/도도/도도 종단경사/테스트베드/sementic_1'\n",
    "\n",
    "origin = np.array([0.0, 0.0, -2.27], dtype=np.float32) # Set vehicle origin coordinates\n",
    "\n",
    "road_rgb = np.array([128, 64, 128])  # Road color (RGB threshold)\n",
    "\n",
    "BASE_POINT   = np.array([0.0, 0.0, -2.27], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb4404",
   "metadata": {},
   "source": [
    "## Define preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082ad13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions required for preprocessing\n",
    "\n",
    "# 1. Define PCD reader (xyz + intensity)\n",
    "def read_pcd_xyz_intensity(path):\n",
    "    pcd_t = o3d.t.io.read_point_cloud(path)\n",
    "    xyz = pcd_t.point['positions'].numpy().astype(np.float32)\n",
    "    if 'intensity' in pcd_t.point:\n",
    "        intensity = pcd_t.point['intensity'].numpy().astype(np.float32).flatten()\n",
    "    else:\n",
    "        raise ValueError(\"intensity 필드가 존재하지 않습니다.\")\n",
    "    return xyz, intensity\n",
    "\n",
    "# 2. Calibration utilities\n",
    "def quat_to_R(w, x, y, z):\n",
    "    return np.array([\n",
    "        [1-2*(y*y+z*z),   2*(x*y - z*w),   2*(x*z + y*w)],\n",
    "        [2*(x*y + z*w),   1-2*(x*x+z*z),   2*(y*z - x*w)],\n",
    "        [2*(x*z - y*w),   2*(y*z + x*w),   1-2*(x*x+y*y)]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "def make_tf(ext):\n",
    "    T = np.eye(4, dtype=np.float32)\n",
    "    T[:3,:3] = quat_to_R(ext[\"w\"], ext[\"x\"], ext[\"y\"], ext[\"z\"])\n",
    "    T[:3,3]  = [ext[\"tx\"], ext[\"ty\"], ext[\"tz\"]]\n",
    "    return T\n",
    "\n",
    "# 3. Load calibration parameters\n",
    "calib_path = '/Users/jiyeonhwang/Downloads/서울대 교통계획연구실/도도/도도 종단경사/지연 test 파일/Calib.json'\n",
    "with open(calib_path, 'r') as f:\n",
    "    calib = json.load(f)\n",
    "\n",
    "intr = calib[\"01_camera\"][\"3_intrinsic\"]\n",
    "extr = calib[\"01_camera\"][\"4_extrinsic\"]\n",
    "\n",
    "K = np.array([\n",
    "    [intr[\"fx\"], intr.get(\"skew\",0.0), intr[\"cx\"]],\n",
    "    [0,           intr[\"fy\"],           intr[\"cy\"]],\n",
    "    [0,           0,                     1     ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "dist = np.array([\n",
    "    intr[\"k1\"], intr[\"k2\"], intr[\"p1\"], intr[\"p2\"], intr.get(\"k3\", 0.0)\n",
    "], dtype=np.float32)\n",
    "\n",
    "tf = make_tf(extr)\n",
    "\n",
    "# 4. Define file paths and ROI\n",
    "\n",
    "ROI_X = (-20.0, 20.0)\n",
    "ROI_Y = (-100.0, 0.0)\n",
    "ROI_Z = (-20.0, 20.0)\n",
    "\n",
    "road_rgb = np.array([128, 64, 128])\n",
    "\n",
    "\n",
    "# # trimming 비율\n",
    "# TRIM_RATIO_X = 0.10\n",
    "# TRIM_RATIO_Z = 0.05\n",
    "\n",
    "# # trim 함수\n",
    "# def trim_extremes(idxs, vals, ratio):\n",
    "#     N = len(idxs)\n",
    "#     k = int(math.floor(ratio * N))\n",
    "#     if N < 2*k+1:\n",
    "#         return idxs\n",
    "#     order = np.argsort(vals[idxs])\n",
    "#     return idxs[order[k:N-k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892a174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of files to process\n",
    "file_list = sorted([f for f in os.listdir(pcd_dir) if f.endswith('pcd')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04969127",
   "metadata": {},
   "source": [
    "## Projection + Alignment Preprocessing Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab82d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/57/dv1c_0xn3xs1tzzxdvgp0pth0000gn/T/ipykernel_7874/1114291487.py:24: RuntimeWarning: invalid value encountered in cast\n",
      "  uv = px.reshape(-1, 2).astype(int)\n",
      "100%|██████████| 100/100 [00:33<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_dict = {} # Save projection and alignment results in data_dict\n",
    "\n",
    "for file_name in tqdm(file_list):\n",
    "    try:\n",
    "        pcd_path = os.path.join(pcd_dir, file_name)\n",
    "        mask_path = os.path.join(mask_dir, file_name.replace('.pcd', '_mask_rgb.png'))\n",
    "\n",
    "        # Load PCD (xyz + intensity)\n",
    "        xyz_all, intensity_all = read_pcd_xyz_intensity(pcd_path)\n",
    "\n",
    "        # Camera alignment (projection)\n",
    "        hom_all = np.hstack([xyz_all, np.ones((len(xyz_all), 1), np.float32)])\n",
    "        cam_all = (tf @ hom_all.T).T[:, :3]\n",
    "        mask_f = cam_all[:, 2] > 0\n",
    "        xyz_all, cam_all = xyz_all[mask_f], cam_all[mask_f]\n",
    "        intensity_all = intensity_all[mask_f]\n",
    "\n",
    "        # Project to 2D image coordinates\n",
    "        px, _ = cv2.projectPoints(cam_all.astype(np.float32),\n",
    "                                  np.zeros((3,1)), np.zeros((3,1)),\n",
    "                                  K, dist)\n",
    "        uv = px.reshape(-1, 2).astype(int)\n",
    "\n",
    "        seg_bgr = cv2.imread(mask_path)\n",
    "        seg_rgb = cv2.cvtColor(seg_bgr, cv2.COLOR_BGR2RGB)\n",
    "        H, W = seg_rgb.shape[:2]\n",
    "\n",
    "        valid = (\n",
    "            (0 <= uv[:,0]) & (uv[:,0] < W) &\n",
    "            (0 <= uv[:,1]) & (uv[:,1] < H)\n",
    "        )\n",
    "        seg_col = np.zeros((len(uv), 3), np.uint8)\n",
    "        seg_col[valid] = seg_rgb[uv[valid,1], uv[valid,0]]\n",
    "\n",
    "        # ROI and road color filtering\n",
    "        roi_mask = (\n",
    "            (ROI_X[0] <= xyz_all[:,0]) & (xyz_all[:,0] <= ROI_X[1]) &\n",
    "            (ROI_Y[0] <= xyz_all[:,1]) & (xyz_all[:,1] <= ROI_Y[1]) &\n",
    "            (ROI_Z[0] <= xyz_all[:,2]) & (xyz_all[:,2] <= ROI_Z[1])\n",
    "        )\n",
    "        sem_road = np.all(np.abs(seg_col.astype(int) - road_rgb) <= 20, axis=1)\n",
    "        candidate_idx = np.where(roi_mask & sem_road)[0]\n",
    "        road_pts = xyz_all[candidate_idx]\n",
    "        intensity_roi = intensity_all[candidate_idx]\n",
    "    \n",
    "        # # trimming\n",
    "        # idx_x  = trim_extremes(np.arange(len(road_pts)), road_pts[:,0], TRIM_RATIO_X)\n",
    "        # idx_xz = trim_extremes(idx_x, road_pts[:,2], TRIM_RATIO_Z)\n",
    "        # final_idx = candidate_idx[idx_xz]\n",
    "        # trimmed_out = np.setdiff1d(candidate_idx, final_idx) # 선택되지 않은 인덱스들 -> trim으로 없어진 영역\n",
    "\n",
    "        # # trim 된거\n",
    "        # road_pts = xyz_all[final_idx]\n",
    "        # intensity_roi = intensity_all[final_idx]\n",
    "\n",
    "        if len(road_pts) == 0:\n",
    "            print(f\"❌ {file_name} : 도로 점 없음\")\n",
    "            continue\n",
    "\n",
    "        # Extract the farthest road point\n",
    "        local_far_idx = np.argmin(road_pts[:,1])\n",
    "        global_far_idx = candidate_idx[local_far_idx]\n",
    "        far_pt = road_pts[local_far_idx]\n",
    "\n",
    "        data_dict[file_name] = { # Store preprocessing results in dictionary\n",
    "            \"xyz_all\": xyz_all,\n",
    "            \"intensity_all\": intensity_all,\n",
    "            \"road_pts\": road_pts,\n",
    "            \"intensity_roi\": intensity_roi,\n",
    "            \"final_idx\": candidate_idx,\n",
    "            \"global_far_idx\": global_far_idx,\n",
    "            \"far_pt\": far_pt\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[에러] {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bec4a7",
   "metadata": {},
   "source": [
    "## Loop for generating normalized features for DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fa013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features only\n",
    "\n",
    "features_dict = {} # Dictionary to store normalized features\n",
    "\n",
    "\n",
    "for i in file_list:\n",
    "    # Combine (N,3) road points with (N,1) intensity -> (N,4)\n",
    "    features = np.hstack([data_dict[i]['road_pts'], data_dict[i]['intensity_roi'].reshape(-1, 1)])\n",
    "    \n",
    "    # Normalize features (x, y, z, intensity have different scales)\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    features_dict[i] = features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d057e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply weights to the normalized features\n",
    "\n",
    "features_w_dict = {} # Dictionary to store weighted features\n",
    "weights = np.array([0.5, 0.5, 4.0, 1.0])\n",
    "\n",
    "for i in file_list:\n",
    "    features_weighted = features_dict[i] * weights\n",
    "    features_w_dict[i] = features_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d1e104",
   "metadata": {},
   "source": [
    "## DBSCAN 1: Using normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c108aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/dv1c_0xn3xs1tzzxdvgp0pth0000gn/T/ipykernel_7874/521401732.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colormap = plt.cm.get_cmap('Set3', len(unique_labels))\n"
     ]
    }
   ],
   "source": [
    "# eps: distance threshold, min_samples: minimum number of points\n",
    "\n",
    "db = DBSCAN(eps=0.3, min_samples=10)\n",
    "labels = db.fit_predict(features_dict[file_list[3]])\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "colors = np.zeros((len(labels), 3)) \n",
    "\n",
    "colormap = plt.cm.get_cmap('Set3', len(unique_labels)) \n",
    "for idx, label in enumerate(unique_labels):\n",
    "    if label == -1:\n",
    "        colors[labels == label] = [0.5, 0.5, 0.5]  # noise points -> gray\n",
    "    else:\n",
    "        colors[labels == label] = colormap(idx)[:3]\n",
    "\n",
    "\n",
    "# Visualization\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(data_dict[file_list[3]]['road_pts'])\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b60961",
   "metadata": {},
   "source": [
    "## Visualize DBSCAN clustering results together with the full point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69882488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/dv1c_0xn3xs1tzzxdvgp0pth0000gn/T/ipykernel_7874/3966926208.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colormap = plt.cm.get_cmap('Set3', len(unique_labels))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_file = file_list[3]\n",
    "\n",
    "db = DBSCAN(eps=0.3, min_samples=10)\n",
    "labels = db.fit_predict(features_dict[target_file])\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "\n",
    "xyz_all      = data_dict[target_file]['xyz_all']     \n",
    "candidate_idx = data_dict[target_file]['final_idx']\n",
    "colors_full = np.ones((len(xyz_all), 3)) * 0.5   \n",
    "\n",
    "\n",
    "colormap = plt.cm.get_cmap('Set3', len(unique_labels))\n",
    "\n",
    "for idx, label in enumerate(unique_labels):\n",
    "\n",
    "    if label == -1:\n",
    "        continue\n",
    "\n",
    "    cluster_color = np.array(colormap(idx)[:3])\n",
    "\n",
    "    local_mask = (labels == label)\n",
    "\n",
    "    global_idx = candidate_idx[local_mask]\n",
    "\n",
    "    colors_full[global_idx] = cluster_color\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz_all)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors_full)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501fbec",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "  <img src=\"./images/364804.999997_Final_4.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703592f",
   "metadata": {},
   "source": [
    "## DBSCAN 2: Using normalized and weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2dcb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/dv1c_0xn3xs1tzzxdvgp0pth0000gn/T/ipykernel_7874/505877789.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colormap_w = plt.cm.get_cmap('Set3', len(unique_labels_w))\n"
     ]
    }
   ],
   "source": [
    "test_file = file_list[3]\n",
    "\n",
    "db_w = DBSCAN(eps=0.2, min_samples=10)\n",
    "labels_w = db_w.fit_predict(features_w_dict[test_file])\n",
    "\n",
    "unique_labels_w = np.unique(labels_w)\n",
    "colors_w = np.zeros((len(labels_w), 3)) \n",
    "\n",
    "colormap_w = plt.cm.get_cmap('Set3', len(unique_labels_w))  \n",
    "for idx_w, label_w in enumerate(unique_labels_w):\n",
    "    if label_w == -1:\n",
    "        colors_w[labels_w == label_w] = [0.5, 0.5, 0.5]\n",
    "    else:\n",
    "        colors_w[labels_w == label_w] = colormap_w(idx_w)[:3]\n",
    "\n",
    "pcd_w = o3d.geometry.PointCloud()\n",
    "pcd_w.points = o3d.utility.Vector3dVector(data_dict[test_file]['road_pts'])\n",
    "pcd_w.colors = o3d.utility.Vector3dVector(colors_w)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_w])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e7489",
   "metadata": {},
   "source": [
    "# Compute longitudinal slope after DBSCAN-based noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a8e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Select the largest cluster (excluding -1 which represents noise)\n",
    "label_counter = Counter(labels_w)\n",
    "label_counter.pop(-1, None)  # remove noise label\n",
    "road_label = label_counter.most_common(1)[0][0]  # label with the most points\n",
    "\n",
    "# Extract only the main road cluster\n",
    "main_road = labels_w == road_label\n",
    "main_road_pts = data_dict[test_file]['road_pts'][main_road]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbf4b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4989)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_far_idx = np.argmin(data_dict[test_file]['road_pts'][:,1])\n",
    "test_far_idx\n",
    "# global_far_idx = candidate_idx[local_far_idx]\n",
    "# far_pt = road_pts[local_far_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5db6f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.738706 , -11.199067 , -12.355909 , ...,  -6.6102333,\n",
       "        -7.166094 ,  -6.880293 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[test_file]['road_pts'][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a9fcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.9195569, -99.54187  ,  -2.7990465], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_far_pts = data_dict[test_file]['road_pts'][test_far_idx]\n",
    "test_far_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa542f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.9195569, -99.54187  ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_far_pts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d16e8e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-2.27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_POINT[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bcacca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.58467 -0.52904654 -0.531253 100.59322\n"
     ]
    }
   ],
   "source": [
    "horiz = np.linalg.norm(test_far_pts[:2] - BASE_POINT[:2])\n",
    "vert  = test_far_pts[2] - BASE_POINT[2]\n",
    "slope_ratio = (vert / horiz)*100 if horiz != 0 else 0.0\n",
    "dist      = np.linalg.norm(far_pt - BASE_POINT)\n",
    "\n",
    "print(horiz, vert, slope_ratio, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c28de6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>slope_percent(%)</th>\n",
       "      <th>distance_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364800.099993.pcd</td>\n",
       "      <td>-0.122479</td>\n",
       "      <td>71.837372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>364802.100011.pcd</td>\n",
       "      <td>-0.318304</td>\n",
       "      <td>66.746185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>364803.700000.pcd</td>\n",
       "      <td>-0.012193</td>\n",
       "      <td>69.414627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>364804.999997.pcd</td>\n",
       "      <td>-0.307521</td>\n",
       "      <td>59.249557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>364806.099978.pcd</td>\n",
       "      <td>-0.498715</td>\n",
       "      <td>58.696812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>367390.900000.pcd</td>\n",
       "      <td>-0.301984</td>\n",
       "      <td>55.855045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>367391.600000.pcd</td>\n",
       "      <td>-0.213143</td>\n",
       "      <td>54.660049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>367392.299998.pcd</td>\n",
       "      <td>-0.886404</td>\n",
       "      <td>58.215660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>367393.000014.pcd</td>\n",
       "      <td>-0.601244</td>\n",
       "      <td>60.295650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>367393.699993.pcd</td>\n",
       "      <td>-0.675602</td>\n",
       "      <td>61.510811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file  slope_percent(%)  distance_m\n",
       "0   364800.099993.pcd         -0.122479   71.837372\n",
       "1   364802.100011.pcd         -0.318304   66.746185\n",
       "2   364803.700000.pcd         -0.012193   69.414627\n",
       "3   364804.999997.pcd         -0.307521   59.249557\n",
       "4   364806.099978.pcd         -0.498715   58.696812\n",
       "..                ...               ...         ...\n",
       "95  367390.900000.pcd         -0.301984   55.855045\n",
       "96  367391.600000.pcd         -0.213143   54.660049\n",
       "97  367392.299998.pcd         -0.886404   58.215660\n",
       "98  367393.000014.pcd         -0.601244   60.295650\n",
       "99  367393.699993.pcd         -0.675602   61.510811\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "BASE_POINT = np.array([0.0, 0.0, -2.27], dtype=np.float32)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fname in file_list:\n",
    "    try:\n",
    "        road_pts = data_dict[fname]['road_pts']\n",
    "        intensity = data_dict[fname]['intensity_roi']\n",
    "\n",
    "        if len(road_pts) < 10:\n",
    "            continue  # Skip files with too few road points\n",
    "\n",
    "        # Normalize + apply feature weights\n",
    "        features = np.hstack([road_pts, intensity.reshape(-1,1)])\n",
    "        features = StandardScaler().fit_transform(features)\n",
    "        weights = np.array([0.5, 0.5, 4.0, 1.0])\n",
    "        features *= weights\n",
    "\n",
    "        # DBSCAN clustering\n",
    "        labels = DBSCAN(eps=0.2, min_samples=10).fit_predict(features)\n",
    "\n",
    "        # Identify the largest cluster (excluding noise)\n",
    "        label_counter = Counter(labels)\n",
    "        label_counter.pop(-1, None)  # remove noise (-1)\n",
    "        if not label_counter:\n",
    "            continue\n",
    "        road_label = label_counter.most_common(1)[0][0]\n",
    "        main_mask = labels == road_label\n",
    "        main_road_pts = road_pts[main_mask]\n",
    "\n",
    "        # Extract the farthest point along the longitudinal axis (min y)\n",
    "        far_idx = np.argmin(main_road_pts[:,1])\n",
    "        far_pt = main_road_pts[far_idx]\n",
    "\n",
    "        # Compute horizontal distance, vertical rise, slope (%), and 3D distance\n",
    "        horiz = np.linalg.norm(far_pt[:2] - BASE_POINT[:2])\n",
    "        vert = far_pt[2] - BASE_POINT[2]\n",
    "        slope = (vert / horiz) * 100 if horiz != 0 else 0.0\n",
    "        dist = np.linalg.norm(far_pt - BASE_POINT)\n",
    "\n",
    "        results.append({\n",
    "            'file': fname,\n",
    "            'slope_percent(%)': slope,\n",
    "            'distance_m': dist\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[에러] {fname}: {e}\")\n",
    "\n",
    "df_result = pd.DataFrame(results)\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
